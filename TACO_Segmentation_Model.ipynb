{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TACO_Segmentation_Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ3GmNtcET0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Imports\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "%matplotlib inline\n",
        "\n",
        "#Imports for models\n",
        "import tensorflow as tf \n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Activation, Input, Conv2DTranspose, Lambda\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "#seed = 42\n",
        "#np.random.seed = seed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhbTb_qEYL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initDataset(folder, classes=None, mode='train'):    \n",
        "    ##Initialize COCO api for instance annotations\n",
        "    annFile = '{}/annotations.json'.format(folder)\n",
        "    coco = COCO(annFile)\n",
        "    \n",
        "    images = []\n",
        "\n",
        "    ##Judging for train/val datasets\n",
        "    if mode == 'train':\n",
        "        imgIds = coco.getImgIds(range(0, 1200))\n",
        "        images = coco.loadImgs(imgIds)\n",
        "\n",
        "    elif mode == 'val':\n",
        "        imgIds = coco.getImgIds(range(1200, 1500))\n",
        "        images = coco.loadImgs(imgIds)\n",
        "                \n",
        "    random.shuffle(images)\n",
        "    dataset_size = len(images)\n",
        "    \n",
        "    return images, dataset_size, coco"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xqlSc01HXsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "da3f7eaa-b6bd-41cd-85b9-a7c1cc937775"
      },
      "source": [
        "annFile = '/content/drive/My Drive/datasets/TACO_Litter/TACO/data/annotations.json'\n",
        "coco_cats = COCO(annFile)\n",
        "catIds = coco_cats.getCatIds()\n",
        "cats = coco_cats.loadCats(catIds)\n",
        "\n",
        "nms = [cat['name'] for cat in cats]\n",
        "print(len(nms), \"COCO Categories: \\n {} \\n\".format(''.join(nms)))\n",
        "print(nms)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.35s)\n",
            "creating index...\n",
            "index created!\n",
            "60 COCO Categories: \n",
            " Aluminium foilBatteryAluminium blister packCarded blister packOther plastic bottleClear plastic bottleGlass bottlePlastic bottle capMetal bottle capBroken glassFood CanAerosolDrink canToilet tubeOther cartonEgg cartonDrink cartonCorrugated cartonMeal cartonPizza boxPaper cupDisposable plastic cupFoam cupGlass cupOther plastic cupFood wasteGlass jarPlastic lidMetal lidOther plasticMagazine paperTissuesWrapping paperNormal paperPaper bagPlastified paper bagPlastic filmSix pack ringsGarbage bagOther plastic wrapperSingle-use carrier bagPolypropylene bagCrisp packetSpread tubTupperwareDisposable food containerFoam food containerOther plastic containerPlastic gloovesPlastic utensilsPop tabRope & stringsScrap metalShoeSqueezable tubePlastic strawPaper strawStyrofoam pieceUnlabeled litterCigarette \n",
            "\n",
            "['Aluminium foil', 'Battery', 'Aluminium blister pack', 'Carded blister pack', 'Other plastic bottle', 'Clear plastic bottle', 'Glass bottle', 'Plastic bottle cap', 'Metal bottle cap', 'Broken glass', 'Food Can', 'Aerosol', 'Drink can', 'Toilet tube', 'Other carton', 'Egg carton', 'Drink carton', 'Corrugated carton', 'Meal carton', 'Pizza box', 'Paper cup', 'Disposable plastic cup', 'Foam cup', 'Glass cup', 'Other plastic cup', 'Food waste', 'Glass jar', 'Plastic lid', 'Metal lid', 'Other plastic', 'Magazine paper', 'Tissues', 'Wrapping paper', 'Normal paper', 'Paper bag', 'Plastified paper bag', 'Plastic film', 'Six pack rings', 'Garbage bag', 'Other plastic wrapper', 'Single-use carrier bag', 'Polypropylene bag', 'Crisp packet', 'Spread tub', 'Tupperware', 'Disposable food container', 'Foam food container', 'Other plastic container', 'Plastic glooves', 'Plastic utensils', 'Pop tab', 'Rope & strings', 'Scrap metal', 'Shoe', 'Squeezable tube', 'Plastic straw', 'Paper straw', 'Styrofoam piece', 'Unlabeled litter', 'Cigarette']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XBXv1dJl8ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getClassName(classID, cats):\n",
        "    for i in range(len(cats)):\n",
        "        if cats[i]['id']==classID:\n",
        "            return cats[i]['name']\n",
        "    return None\n",
        "\n",
        "def getImage(imageObj, img_folder, input_image_size):\n",
        "    ##Read and normalize an image\n",
        "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
        "    ##Resize\n",
        "    train_img = cv2.resize(train_img, input_image_size)\n",
        "    if (len(train_img.shape)==3 and train_img.shape[2]==3): ##If it is a RGB 3 channel image\n",
        "        return train_img\n",
        "    else: ##To handle a black and white image, increase dimensions to 3\n",
        "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
        "        return stacked_img\n",
        "    \n",
        "def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    cats = coco.loadCats(catIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        className = getClassName(anns[a]['category_id'], cats)\n",
        "        pixel_value = classes.index(className)+1\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    ##Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask  \n",
        "    \n",
        "def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
        "        \n",
        "        ##Threshold because resizing may cause extraneous values\n",
        "        new_mask[new_mask >= 0.5] = 1\n",
        "        new_mask[new_mask < 0.5] = 0\n",
        "\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    ##Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask\n",
        "\n",
        "\n",
        "def dataGeneratorCoco(images, classes, coco, folder, \n",
        "                      input_image_size=(224,224), batch_size=4, mode='train', mask_type='binary'):\n",
        "    \n",
        "    img_folder = folder + '/'\n",
        "    dataset_size = len(images)\n",
        "    catIds = coco.getCatIds()\n",
        "    \n",
        "    c = 0\n",
        "    while(True):\n",
        "        img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
        "        mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
        "\n",
        "        for i in range(c, c+batch_size): ##Initially from 0 to batch_size, when c = 0\n",
        "            imageObj = images[i]\n",
        "            \n",
        "            ###Retrieve Image\n",
        "            train_img = getImage(imageObj, img_folder, input_image_size)\n",
        "            \n",
        "            ###Create Mask\n",
        "            if mask_type==\"binary\":\n",
        "                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
        "            \n",
        "            elif mask_type==\"normal\":\n",
        "                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
        "            \n",
        "            ##Add to respective batch sized arrays\n",
        "            img[i-c] = train_img\n",
        "            mask[i-c] = train_mask\n",
        "            \n",
        "        c+=batch_size\n",
        "        if(c + batch_size >= dataset_size):\n",
        "            c=0\n",
        "            random.shuffle(images)\n",
        "        yield img, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GalXhkREhDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augmentationsGenerator(gen, augGeneratorArgs, seed=None):\n",
        "    ##Initialize the image data generator with args provided\n",
        "    image_gen = ImageDataGenerator(**augGeneratorArgs)\n",
        "    \n",
        "    ##Remove the brightness argument for the mask. Spatial arguments similar to image.\n",
        "    augGeneratorArgs_mask = augGeneratorArgs.copy()\n",
        "    _ = augGeneratorArgs_mask.pop('brightness_range', None)\n",
        "\n",
        "    ##Initialize the mask data generator with modified args\n",
        "    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n",
        "    \n",
        "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
        "    \n",
        "    for img, mask in gen:\n",
        "        seed = np.random.choice(range(9999))\n",
        "        ##Keeping the seeds syncronized otherwise the augmentation of the images will end up different from the augmentation of the masks\n",
        "        g_x = image_gen.flow(255*img, \n",
        "                             batch_size = img.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "        g_y = mask_gen.flow(mask, \n",
        "                             batch_size = mask.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "        \n",
        "        img_aug = next(g_x)/255.0\n",
        "        \n",
        "        mask_aug = next(g_y)\n",
        "                   \n",
        "\n",
        "        yield img_aug, mask_aug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2NoicwSn2U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augGeneratorArgs = dict(featurewise_center = False, \n",
        "                        samplewise_center = False,\n",
        "                        rotation_range = 5, \n",
        "                        width_shift_range = 0.01, \n",
        "                        height_shift_range = 0.01, \n",
        "                        brightness_range = (0.8,1.2),\n",
        "                        shear_range = 0.01,\n",
        "                        zoom_range = [1, 1.25],  \n",
        "                        horizontal_flip = True, \n",
        "                        vertical_flip = False,\n",
        "                        fill_mode = 'reflect',\n",
        "                        data_format = 'channels_last')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il5_MHM4o09M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualizeGenerator(gen):\n",
        "    img, mask = next(gen)\n",
        "    \n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    outerGrid = gridspec.GridSpec(1, 2, wspace=0.1, hspace=0.1)\n",
        "    \n",
        "    for i in range(2):\n",
        "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 2,\n",
        "                        subplot_spec=outerGrid[i], wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for j in range(4):\n",
        "            ax = plt.Subplot(fig, innerGrid[j])\n",
        "            if(i==1):\n",
        "                ax.imshow(img[j])\n",
        "            else:\n",
        "                ax.imshow(mask[j][:,:,0])\n",
        "                \n",
        "            ax.axis('off')\n",
        "            fig.add_subplot(ax)        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8GnkV1do1Uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualizeGenerator(train_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWyVWqDEj0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "703fc92d-5d27-4c34-a094-431717484a34"
      },
      "source": [
        "###Model time!\n",
        "\n",
        "#Defining variables\n",
        "\n",
        "annFile = '/content/drive/My Drive/datasets/TACO_Litter/TACO/data/annotations.json'\n",
        "coco_cats = COCO(annFile)\n",
        "catIds = coco_cats.getCatIds()\n",
        "cats = coco_cats.loadCats(catIds)\n",
        "\n",
        "_classes = nms\n",
        "train = 'train'\n",
        "val = 'val'\n",
        "input_image_size = (224, 224)\n",
        "batch_size = 8\n",
        "binary = 'binary'\n",
        "normal = 'normal'\n",
        "dataDir = '/content/drive/My Drive/datasets/TACO_Litter/TACO/data'\n",
        "\n",
        "\n",
        "##Creating train dataset\n",
        "train_set, train_size, coco_train = initDataset(dataDir, _classes, train)\n",
        "\n",
        "##Creating val dataset\n",
        "val_set, val_size, coco_val = initDataset(dataDir, _classes, val)\n",
        "\n",
        "##Train generator\n",
        "#val_gen = dataGeneratorCoco(images, classes, coco, dataDir, input_image_size, batch_size, mode, mask_type)\n",
        "train_gen = dataGeneratorCoco(train_set, _classes, coco_train, dataDir, input_image_size, batch_size, train, normal)\n",
        "\n",
        "##Val generator\n",
        "val_gen = dataGeneratorCoco(val_set, _classes, coco_val, dataDir, input_image_size, batch_size, val, normal)\n",
        "\n",
        "##Augmenting train generator\n",
        "train_gen_aug = augmentationsGenerator(train_gen, augGeneratorArgs)\n",
        "\n",
        "##Augmenting val generator\n",
        "val_gen_aug = augmentationsGenerator(val_gen, augGeneratorArgs)\n",
        "\n",
        "print(train_size, val_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "1200 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rji-aEbJmXLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Resetting and defining logs\n",
        "!rm -rf '/content/drive/My Drive/THESIS/taco_logs3'\n",
        "!mkdir '/content/drive/My Drive/THESIS/taco_logs3'\n",
        "logs = '/content/drive/My Drive/THESIS/taco_logs3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzBs6hAPEoGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce6d280b-5570-4af6-ad4a-c2e7fe4310ed"
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "IMG_CHANNELS = 3\n",
        "epochs = 25\n",
        "validation_steps = val_size\n",
        "steps_per_epoch = train_size\n",
        "x = 64\n",
        "\n",
        "##Creating the model\n",
        "\n",
        "initializer = \"he_normal\"\n",
        "\n",
        "###Building U-Net Model\n",
        "\n",
        "##Input Layer\n",
        "inputs = Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
        "\n",
        "##Converting inputs to float\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "##Contraction\n",
        "c1 = tf.keras.layers.Conv2D(x, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(x, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(x*2, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(x*2, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(x*4, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(x*4, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(x*8, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(x*8, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(x*16, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(x*16, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c5)\n",
        "\n",
        "##Expansion\n",
        "u6 = tf.keras.layers.Conv2DTranspose(x*8, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(x*8, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(x*8, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(x*4, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(x*4, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(x*4, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(x*2, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(x*2, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(x*2, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(x, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(x, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(x, (3,3), activation=\"relu\", kernel_initializer=initializer, padding=\"same\")(c9)\n",
        "\n",
        "##Output Layer\n",
        "outputs = tf.keras.layers.Conv2D(61, (1,1), activation=\"softmax\")(c9)\n",
        "\n",
        "##Defining Model\n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "##Compiling Model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "##Calling Model Summary\n",
        "model.summary()\n",
        "\n",
        "##Defining callbacks\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/THESIS/taco_2-2_final_retry_64.h5', verbose=1, save_best_only=True),\n",
        "             tf.keras.callbacks.EarlyStopping(patience=6, monitor=\"val_loss\"),\n",
        "             tf.keras.callbacks.TensorBoard(log_dir=logs),\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience = 2, min_lr = 0.001)]\n",
        "\n",
        "##Training the modelEpoch 1/25\n",
        "results = model.fit(x = train_gen_aug, \n",
        "                    validation_data = val_gen_aug, \n",
        "                    steps_per_epoch = steps_per_epoch, \n",
        "                    validation_steps = validation_steps, \n",
        "                    epochs = epochs, \n",
        "                    callbacks=callbacks,\n",
        "                    verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 224, 224, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 224, 224, 64) 1792        lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 224, 224, 64) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 224, 224, 64) 36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 112, 112, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 112, 112, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 112, 112, 128 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 112, 112, 128 147584      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 56, 56, 256)  295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 56, 56, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 56, 56, 256)  590080      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 512)  1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 28, 28, 512)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 512)  2359808     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 14, 14, 1024) 4719616     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 14, 14, 1024) 0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 14, 14, 1024) 9438208     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 28, 28, 512)  2097664     conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 28, 28, 1024) 0           conv2d_transpose[0][0]           \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 28, 28, 512)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 512)  2359808     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 56, 56, 256)  524544      conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 56, 56, 512)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 56, 56, 256)  1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 56, 56, 256)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 56, 56, 256)  590080      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 112, 112, 128 131200      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 112, 112, 256 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 112, 112, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 112, 112, 128 0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 112, 112, 128 147584      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 224, 224, 64) 32832       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 224, 224, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 224, 224, 64) 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 224, 224, 64) 0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 224, 224, 64) 36928       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 224, 224, 61) 3965        conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,035,645\n",
            "Trainable params: 31,035,645\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/25\n",
            " 855/1200 [====================>.........] - ETA: 3:53:08 - loss: 0.8121 - sparse_categorical_accuracy: 0.9487"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc2ZZ7K8o78n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Loading partially trained model and continuing training\n",
        "taco = tf.keras.models.load_model('/content/drive/My Drive/THESIS/taco_2-2_final_retry.h5')\n",
        "history = taco.fit(x = train_gen_aug, \n",
        "                    validation_data = val_gen_aug, \n",
        "                    steps_per_epoch = steps_per_epoch, \n",
        "                    validation_steps = validation_steps, \n",
        "                    epochs = epochs, \n",
        "                    callbacks=callbacks,\n",
        "                    verbose = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzG6g75TIy9_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}